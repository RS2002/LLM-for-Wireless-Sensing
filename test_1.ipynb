{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d049bcee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"status_code\": 200, \"request_id\": \"6b91d18f-9e36-9694-97f0-ab85d0f80a2a\", \"code\": \"\", \"message\": \"\", \"output\": {\"text\": null, \"finish_reason\": null, \"choices\": [{\"finish_reason\": \"stop\", \"message\": {\"role\": \"assistant\", \"content\": \" Sure! I have learned 12 pairs of tokens and labels so far.\", \"content_type\": \"text\"}}]}, \"usage\": {\"input_tokens\": 1972, \"output_tokens\": 18}}\n",
      "{\"status_code\": 200, \"request_id\": \"f56e9bd8-aa1d-9a1c-b29a-3e38749614cd\", \"code\": \"\", \"message\": \"\", \"output\": {\"text\": null, \"finish_reason\": null, \"choices\": [{\"finish_reason\": \"stop\", \"message\": {\"role\": \"assistant\", \"content\": \" Sure! I have learned 24 pairs of tokens and labels so far.\", \"content_type\": \"text\"}}]}, \"usage\": {\"input_tokens\": 3818, \"output_tokens\": 18}}\n",
      "Llama model training completed.\n"
     ]
    }
   ],
   "source": [
    "from http import HTTPStatus\n",
    "import dashscope\n",
    "import numpy as np\n",
    "\n",
    "api = 'sk-c38104258eae4578b8cdbd27c32d5ba9'  # 替换为API KEY\n",
    "dashscope.api_key = api\n",
    "\n",
    "# Load data\n",
    "token_path = './data/csi_token.npy'\n",
    "label_path = './data/people.npy'\n",
    "\n",
    "tokens = np.load(token_path)\n",
    "labels = np.load(label_path)\n",
    "\n",
    "# Set prompt for training\n",
    "prompt_train = '''You are a classifier. I have a series of tokens which belong to four labels.\n",
    "You will be given multiple tokens and corresponding labels in our following dialogues.\n",
    "In every round of dialogue, I will give you 13 pairs of tokens and labels and you need to learn them.\n",
    "If you have learned these two kinds of data well,you only need to answer directly with numbers how many pairs of \n",
    "tokens and labels you have learned from all the previous dialogues so far,no any other words!!!only a single number'''\n",
    "\n",
    "# Batch size for training in each round\n",
    "batch_size = 12\n",
    "# Create messages for the batch\n",
    "messages = [{'role': 'system', 'content': prompt_train}]\n",
    "\n",
    "# Loop through your data for training with batch_size\n",
    "for batch_start in range(0, 24, batch_size):\n",
    "    batch_end = min(batch_start + batch_size, 24)\n",
    "    \n",
    "    # Prepare batch data\n",
    "    batch_tokens = tokens[batch_start:batch_end]\n",
    "    batch_labels = labels[batch_start:batch_end]\n",
    "\n",
    "    # Construct a single user message with information from all data points\n",
    "    user_content = '\\n'.join([f'This is the token{i+batch_start}: {str(batch_tokens[i,:,:])}. And this is its label{i+batch_start}: {str(batch_labels[i])},I have given you {i+batch_start+1} pairs of tokens and labels.' for i in range(len(batch_tokens))])\n",
    "    #print(user_content)\n",
    "    user_message = {'role': 'user', 'content': user_content}\n",
    "    messages.append(user_message)\n",
    "\n",
    "    # Call the DashScope API for training\n",
    "    response = dashscope.Generation.call(\n",
    "        model='llama2-13b-chat-v2',\n",
    "        messages=messages,\n",
    "        result_format='message',\n",
    "    )\n",
    "\n",
    "    if response.status_code != HTTPStatus.OK:\n",
    "        print(f'Request id: {response.request_id}, Status code: {response.status_code}, Error code: {response.code}, Error message: {response.message}')\n",
    "    else:\n",
    "        # Check if 'choices' is present in the response\n",
    "        if 'choices' in response.output:\n",
    "            # Optionally, you can append the model's response to the messages list\n",
    "            response_message = {'role': response.output.choices[0]['message']['role'],\n",
    "                                'content': response.output.choices[0]['message']['content']}\n",
    "            messages.append(response_message)\n",
    "            print(response)\n",
    "        else:\n",
    "            print(f'Error: Model response does not contain \"choices\" attribute.')\n",
    "\n",
    "# Training completed\n",
    "print('Llama model training completed.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35286b58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
